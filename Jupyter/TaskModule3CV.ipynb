{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9445de1-ef63-4f21-bdde-330f0d969084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\abdur\\anaconda3\\envs\\tf-env\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\abdur\\anaconda3\\envs\\tf-env\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\abdur\\anaconda3\\envs\\tf-env\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\abdur\\anaconda3\\envs\\tf-env\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abdur\\anaconda3\\envs\\tf-env\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\abdur\\anaconda3\\envs\\tf-env\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\abdur\\anaconda3\\envs\\tf-env\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\abdur\\anaconda3\\envs\\tf-env\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abdur\\anaconda3\\envs\\tf-env\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49dff722-e638-440a-af33-d81aafc32274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\abdur\\anaconda3\\envs\\tf-env\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\abdur\\anaconda3\\envs\\tf-env\\lib\\site-packages (from torchvision) (1.23.4)\n",
      "Requirement already satisfied: torch==2.5.1 in c:\\users\\abdur\\anaconda3\\envs\\tf-env\\lib\\site-packages (from torchvision) (2.5.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\abdur\\anaconda3\\envs\\tf-env\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\abdur\\anaconda3\\envs\\tf-env\\lib\\site-packages (from torch==2.5.1->torchvision) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\abdur\\anaconda3\\envs\\tf-env\\lib\\site-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\abdur\\anaconda3\\envs\\tf-env\\lib\\site-packages (from torch==2.5.1->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abdur\\anaconda3\\envs\\tf-env\\lib\\site-packages (from torch==2.5.1->torchvision) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\abdur\\anaconda3\\envs\\tf-env\\lib\\site-packages (from torch==2.5.1->torchvision) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\abdur\\anaconda3\\envs\\tf-env\\lib\\site-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\abdur\\anaconda3\\envs\\tf-env\\lib\\site-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abdur\\anaconda3\\envs\\tf-env\\lib\\site-packages (from jinja2->torch==2.5.1->torchvision) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60094b57-253b-499a-bfc0-7ed8bafbb66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\abdur\\anaconda3\\envs\\tf-env\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\abdur\\anaconda3\\envs\\tf-env\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "478369a8-141e-430d-a26f-d6ca62928713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in c:\\users\\abdur\\anaconda3\\envs\\tf-env\\lib\\site-packages (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "# Codeblock 1\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Codeblock 2\n",
    "!pip install torchinfo\n",
    "from torchinfo import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fdc9c35-af79-4fc3-95f4-b63374f0aa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Transform for CIFAR-10 (RGB images)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83b55701-5e1c-4ece-ba90-51b596af2324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27fbd90a-cdb1-412d-a45b-2d2cbd4ccb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0c70428-acb4-494f-b054-b429f9339fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and evaluation functions\n",
    "def train_model(model, loss_function, optimizer, have_aux=False, epochs=5):\n",
    "    train_losses, test_losses = [], []\n",
    "    train_accs, test_accs = [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        num_correct_train, num_samples_train = 0, 0\n",
    "        for batch, (x_train, y_train) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "            x_train, y_train = x_train.to(device), y_train.to(device)\n",
    "            \n",
    "            if have_aux:\n",
    "                train_preds = model(x_train)[0] \n",
    "            else:\n",
    "                train_preds = model(x_train)\n",
    "            train_loss = loss_function(train_preds, y_train)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                predicted_labels = torch.max(train_preds, dim=1)[1]\n",
    "                num_correct_train += (predicted_labels == y_train).sum().item()\n",
    "                num_samples_train += y_train.size(0)\n",
    "            \n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_acc = num_correct_train / num_samples_train\n",
    "        test_loss, test_acc = predict_test_data(model, test_loader, loss_function)\n",
    "        \n",
    "        train_losses.append(train_loss.item())\n",
    "        test_losses.append(test_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        test_accs.append(test_acc)\n",
    "\n",
    "        print(f'Epoch: {epoch + 1} | Train Loss: {train_loss.item():.3f} | Test Loss: {test_loss:.3f} | '\n",
    "              f'Train Acc: {train_acc:.2f} | Test Acc: {test_acc:.2f}')\n",
    "    \n",
    "    return model, train_losses, test_losses, train_accs, test_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "166fd7e4-9542-4b72-8b07-fd573ad5741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c46100f-a775-4104-94bb-238f2613c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_data(model, test_loader, loss_function):\n",
    "    model.eval()\n",
    "    num_correct, num_samples = 0, 0\n",
    "    test_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_test, y_test in test_loader:\n",
    "            x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "            test_preds = model(x_test)\n",
    "            test_loss += loss_function(test_preds, y_test).item()\n",
    "            \n",
    "            predicted_labels = torch.max(test_preds, dim=1)[1]\n",
    "            num_correct += (predicted_labels == y_test).sum().item()\n",
    "            num_samples += y_test.size(0)\n",
    "    \n",
    "    model.train()\n",
    "    test_acc = num_correct / num_samples\n",
    "    return test_loss / len(test_loader), test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8504dcdd-ba62-4078-89ce-ad2cfe1ffed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdur\\anaconda3\\envs\\tf-env\\lib\\site-packages\\torchvision\\models\\googlenet.py:341: UserWarning: auxiliary heads in the pretrained googlenet model are NOT pretrained, so make sure to train them\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet18, googlenet, vgg11, mobilenet_v3_small, alexnet\n",
    "from torchvision.models import ResNet18_Weights, GoogLeNet_Weights, VGG11_Weights, MobileNet_V3_Small_Weights, AlexNet_Weights\n",
    "\n",
    "# Load models\n",
    "resnet = resnet18(weights=ResNet18_Weights.DEFAULT).to(device)\n",
    "resnet.fc = nn.Linear(in_features=512, out_features=10).to(device)\n",
    "\n",
    "# GoogLeNet with auxiliary logits enabled (use them for training)\n",
    "googlenet = googlenet(weights=GoogLeNet_Weights.DEFAULT, aux_logits=True).to(device)\n",
    "googlenet.fc = nn.Linear(in_features=1024, out_features=10).to(device)\n",
    "\n",
    "vgg = vgg11(weights=VGG11_Weights.DEFAULT).to(device)\n",
    "vgg.classifier[6] = nn.Linear(in_features=4096, out_features=10).to(device)\n",
    "\n",
    "mobilenet = mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.DEFAULT).to(device)\n",
    "mobilenet.classifier[3] = nn.Linear(in_features=1024, out_features=10).to(device)\n",
    "\n",
    "alexnet = alexnet(weights=AlexNet_Weights.DEFAULT).to(device)\n",
    "alexnet.classifier[6] = nn.Linear(in_features=4096, out_features=10).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d0b2c38-a77e-47ba-ae3d-b7e1107111bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Modify each model for CIFAR-10 (10 classes)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodels_dict\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresnet\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m name\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgooglenet\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m name\u001b[38;5;241m.\u001b[39mlower():\n\u001b[0;32m      4\u001b[0m         model\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(model\u001b[38;5;241m.\u001b[39mfc\u001b[38;5;241m.\u001b[39min_features, \u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'models_dict' is not defined"
     ]
    }
   ],
   "source": [
    "# Modify each model for CIFAR-10 (10 classes)\n",
    "for name, model in models_dict.items():\n",
    "    if \"resnet\" in name.lower() or \"googlenet\" in name.lower():\n",
    "        model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "    elif \"vgg\" in name.lower() or \"alexnet\" in name.lower() or \"mobilenet\" in name.lower():\n",
    "        model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, 10)\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e28553f-a142-4cdc-aef7-ea1ecc7af0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet18 successfully modified for CIFAR-10!\n",
      "googlenet successfully modified for CIFAR-10!\n",
      "vgg11 successfully modified for CIFAR-10!\n",
      "mobilenet_v3_small successfully modified for CIFAR-10!\n",
      "alexnet successfully modified for CIFAR-10!\n"
     ]
    }
   ],
   "source": [
    "# Pastikan device didefinisikan\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Import model dan weight\n",
    "from torchvision.models import resnet18, googlenet, vgg11, mobilenet_v3_small, alexnet\n",
    "from torchvision.models import ResNet18_Weights, GoogLeNet_Weights, VGG11_Weights, MobileNet_V3_Small_Weights, AlexNet_Weights\n",
    "\n",
    "# Load model dan assign ke dictionary\n",
    "models_dict = {\n",
    "    \"resnet18\": resnet18(weights=ResNet18_Weights.DEFAULT).to(device),\n",
    "    \"googlenet\": googlenet(weights=GoogLeNet_Weights.DEFAULT, aux_logits=True).to(device),\n",
    "    \"vgg11\": vgg11(weights=VGG11_Weights.DEFAULT).to(device),\n",
    "    \"mobilenet_v3_small\": mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.DEFAULT).to(device),\n",
    "    \"alexnet\": alexnet(weights=AlexNet_Weights.DEFAULT).to(device),\n",
    "}\n",
    "\n",
    "# Modify setiap model untuk CIFAR-10 (10 classes)\n",
    "for name, model in models_dict.items():\n",
    "    if \"resnet\" in name.lower() or \"googlenet\" in name.lower():\n",
    "        model.fc = nn.Linear(model.fc.in_features, 10).to(device)\n",
    "    elif \"vgg\" in name.lower() or \"alexnet\" in name.lower() or \"mobilenet\" in name.lower():\n",
    "        model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, 10).to(device)\n",
    "\n",
    "# Konfirmasi model berhasil dimodifikasi\n",
    "for name, model in models_dict.items():\n",
    "    print(f\"{name} successfully modified for CIFAR-10!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9d9b29d-9aa5-4175-8e71-f863a40b3797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 781/781 [36:22<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 1.174 | Test Loss: 1.222 | Train Acc: 0.50 | Test Acc: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 781/781 [36:41<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Train Loss: 0.702 | Test Loss: 0.797 | Train Acc: 0.70 | Test Acc: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 781/781 [36:45<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Train Loss: 0.563 | Test Loss: 0.728 | Train Acc: 0.78 | Test Acc: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 781/781 [36:51<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Train Loss: 0.377 | Test Loss: 0.677 | Train Acc: 0.83 | Test Acc: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 781/781 [37:19<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Train Loss: 0.362 | Test Loss: 0.522 | Train Acc: 0.86 | Test Acc: 0.82\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train ResNet\n",
    "resnet = models.resnet18().to(device)\n",
    "resnet.fc = nn.Linear(in_features=512, out_features=10).to(device)\n",
    "optim_resnet = optim.Adam(resnet.parameters(), lr=0.001)\n",
    "resnet_history = train_model(resnet, loss_function, optim_resnet, have_aux=False, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f05770-99b9-4252-861f-3903216821e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 781/781 [54:28<00:00,  4.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 1.328 | Test Loss: 1.366 | Train Acc: 0.42 | Test Acc: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████████████████████████████████████▌      | 716/781 [1:02:44<06:15,  5.77s/it]"
     ]
    }
   ],
   "source": [
    "# Train GoogLeNet\n",
    "googlenet = models.googlenet(aux_logits=True, init_weights=True).to(device)\n",
    "googlenet.fc = nn.Linear(in_features=1024, out_features=10).to(device)\n",
    "optim_googlenet = optim.Adam(googlenet.parameters(), lr=0.001)\n",
    "googlenet_history = train_model(googlenet, loss_function, optim_googlenet, have_aux=True, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b45f779-2f70-4def-9666-8458886f0025",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train VGG\n",
    "vgg = models.vgg11().to(device)\n",
    "vgg.classifier[6] = nn.Linear(in_features=4096, out_features=10).to(device)\n",
    "optim_vgg = optim.Adam(vgg.parameters(), lr=0.001)\n",
    "vgg_history = train_model(vgg, loss_function, optim_vgg, have_aux=False, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3466bd-c998-48c3-b29f-4103f0cc75d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train MobileNet\n",
    "mobilenet = models.mobilenet_v3_small().to(device)\n",
    "mobilenet.classifier[3] = nn.Linear(in_features=1024, out_features=10).to(device)\n",
    "optim_mobilenet = optim.Adam(mobilenet.parameters(), lr=0.001)\n",
    "mobilenet_history = train_model(mobilenet, loss_function, optim_mobilenet, have_aux=False, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6f7e21-6251-4c6d-ade8-a21a7a8c5e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train AlexNet\n",
    "alexnet = models.alexnet().to(device)\n",
    "alexnet.classifier[6] = nn.Linear(in_features=4096, out_features=10).to(device)\n",
    "optim_alexnet = optim.Adam(alexnet.parameters(), lr=0.001)\n",
    "alexnet_history = train_model(alexnet, loss_function, optim_alexnet, have_aux=False, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08505c76-7689-4a22-b240-99937646d395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "for name in results.keys():\n",
    "    plt.plot(results[name][\"test_acc\"], label=name)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.title(\"Test Accuracy Comparison\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378b5bf2-9189-4588-8c46-2cf30a256ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Explanation: \n",
    "The results show that ResNet18 performs better due to its residual connections, which \n",
    "help in optimizing deeper networks by mitigating vanishing gradient issues. GoogLeNet's \n",
    "inception modules also enable it to perform well by combining multiple feature scales. \n",
    "VGG11, being a simpler architecture with deeper layers, performs moderately well, while \n",
    "MobileNetV3 is optimized for efficiency but still provides good results. AlexNet, being an \n",
    "older model, lags due to its relatively shallow and less optimized architecture. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
